**Problem Statement**

Online threats and harassment are on the rise
Harassment can take many forms: bullying, hate speech, sexual harassment, and harmful behavior.

TikTok, with its massive user base, faces unique challenges in monitoring and moderating harmful content at scale.
Difficulties in identifying harmful content in real-time due to the sheer volume of posts and the complexity of language (e.g., slang, emojis).
Increased risks to user mental health → vulnerable users, including teens and marginalized groups.

**Importance of Detecting Harmful Content**

Early detection helps prevent harm by flagging inappropriate content before it escalates.
Protects users' well-being by identifying and addressing harmful language.
Streamlines content moderation, making it easier to spot and address harmful posts.
Supports platform safety policies and enforces community guidelines for safer online spaces.
Ensures accountability by tracking and addressing harassment.
Promotes healthier online environments by reducing toxicity.

**Project Goals:**

Detect harmful content in comments by analyzing sentiment, keywords, and emojis.
Target harmful behaviors such as hate speech, harassment, and bullying to promote safer online spaces.

**CHALLENGE: FORENSIC SCIENCE**

Digital Forensics Contribution: Identifies and flags harmful content, like hate speech and harassment, on platforms like TikTok for investigation.
Digital Evidence Gathering: Analyzes comments, emojis, and sentiment to identify digital “clues” of harassment or abuse, akin to forensic evidence collection.
Accuracy in Detection: Uses multiple methods—sentiment analysis, harmful keyword detection, and emoji analysis—for accurate and automated detection, ensuring consistent results.
Real-World Impact: Addresses the rise in online harassment and threats, providing timely interventions and supporting investigations into digital criminal activities like cyberbullying. 
